{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"kipoiseq Standard set of data-loaders for training and making predictions for DNA sequence-based models. All dataloaders in kipoiseq.datasets decorated with @kipoi_dataloader are compatible Kipoi models and can be directly used when specifying a new model in model.yaml : ... default_dataloader: defined_as: kipoiseq.datasets.SeqDataset default_args: auto_resize_len: 1000 # always resize to 1kb dependencies: pip: - kipoiseq ... Installation pip install kipoiseq Usage from kipoiseq.datasets import SeqDataset dl = SeqDataset.init_example() # use the provided example files # your own files dl = SeqDataset(\"intervals.bed\", \"genome.fa\") len(dl) # length of the dataset dl[0] # get one instance. # returns a dictionary: # dict(inputs=<one-hot-encoded-array>, # targets=<additional columns in the bed file>, # metadata=dict(ranges=GenomicRanges(chr=, start, end)... all = dl.load_all() # load the whole dataset # load batches of data it = dl.batch_iter(32, num_workers=8) # load batches of data in parallel using 8 workers # returns a dictionary with all three keys: inputs, targets, metadata it = dl.batch_train_iter(32, num_workers=8) # returns a tuple: (inputs, targets), can be used directly with keras' `model.fit_generator` How to write your own dataloaders Read the pytorch Data Loading and Processing Tutorial to become more familiar with transforms and datasets Read the code for SeqDataset in kipoiseq/datasets/sequence.py you can skip the @kipoi_dataloader and the long yaml doc-string. These are only required if you want to use dataloaders in Kipoi's model.yaml files. Explore the available transforms ( functional , class-based ) or extractors ( kipoiseq , genomelake )","title":"Home"},{"location":"#kipoiseq","text":"Standard set of data-loaders for training and making predictions for DNA sequence-based models. All dataloaders in kipoiseq.datasets decorated with @kipoi_dataloader are compatible Kipoi models and can be directly used when specifying a new model in model.yaml : ... default_dataloader: defined_as: kipoiseq.datasets.SeqDataset default_args: auto_resize_len: 1000 # always resize to 1kb dependencies: pip: - kipoiseq ...","title":"kipoiseq"},{"location":"#installation","text":"pip install kipoiseq","title":"Installation"},{"location":"#usage","text":"from kipoiseq.datasets import SeqDataset dl = SeqDataset.init_example() # use the provided example files # your own files dl = SeqDataset(\"intervals.bed\", \"genome.fa\") len(dl) # length of the dataset dl[0] # get one instance. # returns a dictionary: # dict(inputs=<one-hot-encoded-array>, # targets=<additional columns in the bed file>, # metadata=dict(ranges=GenomicRanges(chr=, start, end)... all = dl.load_all() # load the whole dataset # load batches of data it = dl.batch_iter(32, num_workers=8) # load batches of data in parallel using 8 workers # returns a dictionary with all three keys: inputs, targets, metadata it = dl.batch_train_iter(32, num_workers=8) # returns a tuple: (inputs, targets), can be used directly with keras' `model.fit_generator`","title":"Usage"},{"location":"#how-to-write-your-own-dataloaders","text":"Read the pytorch Data Loading and Processing Tutorial to become more familiar with transforms and datasets Read the code for SeqDataset in kipoiseq/datasets/sequence.py you can skip the @kipoi_dataloader and the long yaml doc-string. These are only required if you want to use dataloaders in Kipoi's model.yaml files. Explore the available transforms ( functional , class-based ) or extractors ( kipoiseq , genomelake )","title":"How to write your own dataloaders"},{"location":"extractors/","text":"kipoiseq.extractors","title":"Extractors"},{"location":"datasets/sequence/","text":"kipoiseq.datasets.sequence BedDataset BedDataset(self, tsv_file, label_dtype=None, bed_columns=3, num_chr=False, ambiguous_mask=None, incl_chromosomes=None, excl_chromosomes=None) Reads a tsv file in the following format: chr start stop task1 task2 ... Arguments tsv_file : tsv file type bed_columns : number of columns corresponding to the bed file. All the columns after that will be parsed as targets num_chr : if specified, 'chr' in the chromosome name will be dropped label_dtype : specific data type for labels ambiguous_mask : if specified, rows containing only ambiguous_mask values will be skipped incl_chromosomes : exclusive list of chromosome names to include in the final dataset. if not None, only these will be present in the dataset excl_chromosomes : list of chromosome names to omit from the dataset. SeqStringDataset SeqStringDataset(self, intervals_file, fasta_file, num_chr_fasta=False, label_dtype=None, auto_resize_len=None, use_strand=False, force_upper=True) YAML description info: doc: > Dataloader for a combination of fasta and tab-delimited input files such as bed files. The dataloader extracts regions from the fasta file as defined in the tab-delimited `intervals_file`. Returned sequences are of the type np.array([str]). args: intervals_file: doc: bed3+<columns> file path containing intervals + (optionally) labels example: url: https://raw.githubusercontent.com/kipoi/kipoiseq/kipoi_dataloader/tests/data/sample_intervals.bed md5: ecc4cf3885318a108adcc1e491463d36 fasta_file: doc: Reference genome FASTA file path. example: url: https://raw.githubusercontent.com/kipoi/kipoiseq/kipoi_dataloader/tests/data/sample.5kb.fa md5: 6cefc8f443877490ab7bcb66b0872e30 num_chr_fasta: doc: True, the the dataloader will make sure that the chromosomes don't start with chr. label_dtype: doc: None, datatype of the task labels taken from the intervals_file. Allowed - string', 'int', 'float', 'bool' auto_resize_len: doc: None, required sequence length. # max_seq_len: # doc: maximum allowed sequence length use_strand: doc: reverse-complement fasta sequence if bed file defines negative strand force_upper: doc: Force uppercase output of sequences output_schema: inputs: name: seq shape: () doc: DNA sequence as string special_type: DNAStringSeq associated_metadata: ranges targets: shape: (None,) doc: (optional) values following the bed-entry - chr start end target1 target2 .... metadata: ranges: type: GenomicRanges doc: Ranges describing inputs.seq SeqDataset SeqDataset(self, intervals_file, fasta_file, num_chr_fasta=False, label_dtype=None, auto_resize_len=None, use_strand=False, alphabet_axis=1, dummy_axis=None, alphabet='ACGT') YAML description info: doc: > Dataloader for a combination of fasta and tab-delimited input files such as bed files. The dataloader extracts regions from the fasta file as defined in the tab-delimited `intervals_file` and converts them into one-hot encoded format. Returned sequences are of the type np.array with the shape inferred from the arguments: `alphabet_axis` and `dummy_axis`. args: intervals_file: doc: bed3+<columns> file path containing intervals + (optionally) labels example: url: https://raw.githubusercontent.com/kipoi/kipoiseq/kipoi_dataloader/tests/data/sample_intervals.bed md5: ecc4cf3885318a108adcc1e491463d36 fasta_file: doc: Reference genome FASTA file path. example: url: https://raw.githubusercontent.com/kipoi/kipoiseq/kipoi_dataloader/tests/data/sample.5kb.fa md5: 6cefc8f443877490ab7bcb66b0872e30 num_chr_fasta: doc: True, the the dataloader will make sure that the chromosomes don't start with chr. label_dtype: doc: None, datatype of the task labels taken from the intervals_file. Allowed - string', 'int', 'float', 'bool' auto_resize_len: doc: None, required sequence length. example: 3 use_strand: doc: reverse-complement fasta sequence if bed file defines negative strand alphabet_axis: doc: axis along which the alphabet runs (e.g. A,C,G,T for DNA) dummy_axis: doc: defines in which dimension a dummy axis should be added. None if no dummy axis is required. alphabet: doc: > alphabet to use for the one-hot encoding. This defines the order of the one-hot encoding. Can either be a list or a string: 'DNA', 'RNA', 'AMINO_ACIDS'. output_schema: inputs: name: seq shape: (None, 4) doc: One-hot encoded DNA sequence special_type: DNASeq associated_metadata: ranges targets: shape: (None,) doc: (optional) values following the bed-entry - chr start end target1 target2 .... metadata: ranges: type: GenomicRanges doc: Ranges describing inputs.seq","title":"Datsets"},{"location":"transforms/functional/","text":"kipoiseq.transforms.functional one_hot2string one_hot2string(arr, alphabet=['A', 'C', 'G', 'T']) Convert a one-hot encoded array back to string tokenize tokenize(seq, alphabet=['A', 'C', 'G', 'T'], neutral_alphabet=['N']) Convert sequence to integers Arguments seq : Sequence to encode alphabet : Alphabet to use neutral_alphabet : Neutral alphabet -> assign those values to -1 Returns List of length len(seq) with integers from -1 to len(alphabet) - 1 token2one_hot token2one_hot(tokens, alphabet_size=4, neutral_value=0.25) Note: everything out of the alphabet is transformed into np.zeros(alphabet_size) one_hot_dna one_hot_dna(seq) One-hot encode DNA sequence fixed_len fixed_len(seq, length, anchor='center', value='N') Pad and/or trim a list of sequences to have common length. Procedure: Pad the sequence with N's or any other string or list element ( value ) Subset the sequence Note See also: https://keras.io/preprocessing/sequence/ Aplicable also for lists of characters Arguments sequence_vec : list of chars or lists List of sequences that can have various lengths value : Neutral element to pad the sequence with. Can be str or list . length : int or None; Final lenght of sequences. If None, length is set to the longest sequence length. anchor : character; 'start', 'end' or 'center' To which end to anchor the sequences when triming/padding. See examples bellow. Returns List of sequences of the same class as sequence_vec Example >>> sequence = 'CTTACTCAGA' >>> pad_sequence(sequence, 10, anchor=\"start\", value=\"N\") 'CTTACTCAGA' >>> pad_sequence(sequence, 10, anchor=\"end\", value=\"N\") 'CTTACTCAGA' >>> pad_sequences(sequence, 4, anchor=\"center\", value=\"N\") 'ACTC' >>> sequence = 'TCTTTA' >>> pad_sequence(sequence, 10, anchor=\"start\", value=\"N\") 'TCTTTANNNN' >>> pad_sequence(sequence, 10, anchor=\"end\", value=\"N\") 'NNNNTCTTTA' >>> pad_sequences(sequence, 4, anchor=\"center\", value=\"N\") 'CTTT' resize_interval resize_interval(interval, width, anchor='center') Resize the Interval. Returns new Interval instance with correct length. Arguments: interval: pybedtools.Interval object or an object containing start and end attributes width: desired width of the output interval anchor (str): which part of the sequence should be anchored. Choices: 'start', 'center', or 'end'","title":"Functional"},{"location":"transforms/transforms/","text":"kipoiseq.transforms.transforms Compose Compose(self, transforms) Composes several transforms together. Arguments transforms (list of Transform objects) : list of transforms to compose. Example : >>> transforms.Compose([ >>> transforms.CenterCrop(10), >>> transforms.ToTensor(), >>> ]) DummyAxis DummyAxis(self, axis=None) np.expand_dims wrapper - Insert a dummy axis (calls np.expand_dims) SwapAxes SwapAxes(self, axis1=None, axis2=None) np.swapaxes wrapper If any if the axis is None, do nothing. OneHot OneHot(self, alphabet=['A', 'C', 'G', 'T'], neutral_alphabet='N', neutral_value=0.25) One-hot encode the sequence","title":"Class-based"}]}