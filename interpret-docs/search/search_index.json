{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"kipoi_interpret Model interepretation plugin for Kipoi. Installation pip install kipoi_interpret Usage example # list all available methods kipoi_interpret.importance_scores.available_methods() Available methods: # Gradient-based methods from kipoi_interpret.importance_scores.gradient import Gradient, GradientXInput # In-silico mutagenesis-based methods from kipoi_interpret.importance_scores.ism import Mutation # DeepLift from kipoi_interpret.importance_scores.referencebased import DeepLift Gradient * input example # seqa = one-hot-encoded DNA sequence import kipoi model = kipoi.get_model(\"<my-model>\") ginp = GradientXInput(model) val = ginp.score(batch_input) # val is an array of importance scores See notebooks/1-DNA-seq-model-example.ipynb for an example. Release History 0.1.0 First release to PyPI","title":"Home"},{"location":"#kipoi_interpret","text":"Model interepretation plugin for Kipoi.","title":"kipoi_interpret"},{"location":"#installation","text":"pip install kipoi_interpret","title":"Installation"},{"location":"#usage-example","text":"# list all available methods kipoi_interpret.importance_scores.available_methods() Available methods: # Gradient-based methods from kipoi_interpret.importance_scores.gradient import Gradient, GradientXInput # In-silico mutagenesis-based methods from kipoi_interpret.importance_scores.ism import Mutation # DeepLift from kipoi_interpret.importance_scores.referencebased import DeepLift Gradient * input example # seqa = one-hot-encoded DNA sequence import kipoi model = kipoi.get_model(\"<my-model>\") ginp = GradientXInput(model) val = ginp.score(batch_input) # val is an array of importance scores See notebooks/1-DNA-seq-model-example.ipynb for an example.","title":"Usage example"},{"location":"#release-history","text":"0.1.0 First release to PyPI","title":"Release History"},{"location":"overview/","text":"Variant effect prediction Variant effect prediction offers a simple way predict effects of SNVs using any model that uses DNA sequence as an input. Many different scoring methods can be chosen but the principle relies on in-silico mutagenesis (see below). The default input is a VCF and the default output again is a VCF annotated with predictions of variant effects. How it works This sketch highlights the overall functionality of variant effect prediction. More details are given in the chapters below. Dataloader output and a VCF are overlapped and the input DNA sequence is mutated as defined in the VCF. The reference and the alternative set of model inputs is predicted using the model and the differences are evaluated using a scoring function. The results are then stored in an annotated VCF. In-silico mutagenesis The principle relies on generating model predictions twice, once with DNA sequence that contains the reference and once with the alternative allele of a variant. Those predictions can then be compared in different ways to generate an effect prediction. Scoring methods Scoring methods that come with Kipoi are Diff which simply calculates the difference between the two predictions, Logit which calculates the difference of logit(prediction) of the two predictions and a few more. Those scoring methods can also be user-defined in which case they can be submitted with the model. Not all scoring functions are compatible with all model possible model outputs - for example the logit transformation can only be performed on values [0,1]. Model and dataloader requirements The model has to produce predictions at least partly based on DNA sequence and the DNA sequence either has to be as a string (e.g. acgtACGT ) or in a 1-hot encoded way in which A = [1,0,0,0] , C = [0,1,0,0] , G= [0,0,1,0] , T= [0,0,0,1] . Please note that any letter/base that is not in acgtACGT will be regarded and treated as N (in one-hot: [0,0,0,0] )! Requirements for the dataloader are that apart from producing the model input it also has to output information which region of the genome this generated sequence corresponds. On a side note: This region is only used to calculate an overlap with the query VCF, hence as long the dataloader output refers to the same sequence assembly as the VCF file variant scoring will return the desired results. Setting up the model.yaml In order to indicate that a model is compatible with Kipoi postprocessing the definition of postprocessing in the model.yaml file is necessary. The postprocessing section can then mention multiple different ways to interpret a model. Here we will discuss variant effect prediction, a sample section of the model.yaml can look like this: postprocessing: variant_effects: seq_input: - seq use_rc: seq_only This defines that the current model is capable to be used for variant effect prediction ( variant_effects ) and it defines that seq is the name of the model input that contains DNA sequence, which can be mutated and used for effect prediction. seq_input is a mandatory field and variant effect prediction can only be executed if there is at least one model input defined in seq_input . For some models it is necessary that also reverse-complements of DNA sequences are tested / predicted. To indicate that this is the case for the current model add the optional flag use_rc: seq_only . Using seq_only will reverse-complement only the model inputs that are defined in seq_input . Any other model input will remain untouched and exactly the same input will be fed to the model input as for the \"forward\" version of the model input. As mentioned above the DNA sequence input may either be a string or 1-hot encoded. To indicate which format is used the special_type flag is used. The model input may then look like this: schema: inputs: seq: shape: (101, 4) special_type: DNASeq doc: One-hot encoded RNA sequence Here a one-hot encoded sequence ( DNASeq ) is expected to be the model input. Note that the model input label (here: seq ) was used before in the postprocessing section and the same label is expected to be exist in the dataloader output. The special_type flag for using string input sequences is: DNAStringSeq . So the following snippet of a model.yaml file schema: inputs: seq: shape: () special_type: DNAStringSeq doc: RNA sequence as a string indicates that a single sample of seq is np.array(string) where string is a python string. If special_type is not defined for a model input, but it is used in seq_input in the postprocessing section, then by default Kipoi expects one-hot encoded DNA sequences. Setting up the dataloader.yaml Similar to the model.yaml also dataloader.yaml has to have a postprocessing section defined to indicate that it is compatible with variant effect prediction. As a bare minimum the following has to be defined: postprocessing: variant_effects: And equally important every DNA sequence input of a model (here seq ) has to have an associated metadata tag, which could like follows: output_schema: inputs: seq: shape: (101, 4) special_type: DNASeq doc: One-hot encoded RNA sequence associated_metadata: ranges some_other_input: shape: (1, 10) doc: Some description metadata: ranges: type: GenomicRanges doc: Ranges describing inputs.seq Here the associated_metadata flag in the input field seq is set to ranges , which means that for every sample in the model_input['inputs']['seq'] one entry in model_input['metadata']['ranges'] is expected with its type either being GenomicRanges or a dictionary of numpy arrays with the keys chr , start , end , id . The information in the metadata object gives variant effect prediction the possibilty to find the relative position of a variant within a given input sequence. Hence the associated_metadata is mandatory for every entry in seq_input in the model.yaml file. Please note that the coordinates in the metadata are expected to be 0-based, hence comply with .bed file format! The following sketch gives an overview how the different tags play together and how they are used with variant effect prediction. Use-cases This section describes a set of functions which cover most of the common queries for variant effect. All of the functions described below require that the model.yaml and dataloader.yaml files are set up in the way defined above. In literature in-silico mutagenesis-based variant effect predcition is performed in a variant centric way: Starting from a VCF for every variant a sequence centered on said variant is generated. That sequence is then mutated by modifying the central base and setting it to what is defined as reference or alternative allele, generating two sets of sequences. For both the set with the reference allele in the center and the alternative allele in the center the model prediction is run and model outputs are compared. Not all models can predict on aribrary DNA sequences from any region of the genome. Splicing models may for example only be trained on regions surrounding a splice site, hence the variant-centered approach from before will not work. Therefore two more options to run variant effect predicion are offered: restricted variant centered effect prediction and overlap-based effect prediction. Variant effect prediction will try to use variant-centered approaches whenever the bed_input flag is defined in dataloader.yaml (see below). Otherwise the overlap-based effect prediction is used. This is because the variant centered approach is generally faster and for every variant in the VCF one single prediction can be made (assuming the position of variant is in a valid genomic region). For all the methods described below it is essential that genomic coordinates in the VCF and the coordinates used by the dataloader are for the same genome / assembly /etc. Variant centered effect prediction In order to use variant centered effect prediction the dataloader must accept an input bed file based on which it will produce model input. Furthermore the dataloader is required to return the name values (fourth column) of the input bed file in the id field of model_input['metadata']['ranges'] . Additionally the order of samples has to be identical with the order of regions in the input bed file, but regions may be skipped. In order for the variant effect prediction to know which input argument of the dataloader is accepts a bed file three additional lines in dataloader.yaml are necessary, e.g: postprocessing: variant_effects: bed_input: - intervals_file This section indicates that the dataloader function has an argument intervals_file which accepts a bed file path as input which may be used. Restricted-variant centered effect prediction Requirements for the dataloader and dataloader.yaml here are identical to the variant centered effect prediction. The only difference is that this function is designed for models that can't predict on arbitrary regions of the genome, but only in certain regions of the genome. If those regions can be defined in a bed file (further on called 'restriction-bed' file) then this approach can be used. Variant effect prediction will then intersect the VCF with the restriction-bed and generate another bed file that is then passed on to the dataloader. Regions in the restriction-bed file may be larger than the input sequence lenght, in that case the generated seuqence will be centered on the variant position as much as possible - restricted by what is defined in the restrictions-bed file. Overlap-based effect prediction If the dataloader does not support bed input files then variant effect predictions can be run by the overlap of a VCF with the regions defined in the metdata output of the dataloader. If multiple variants overlap with a region then the effect will be predicted inpendently for those variants. If multiple (e.g.: two) model input samples overlap with one variant then the output will contain as many predictions as there were independent overlaps of metadata ranges and variants (e.g.: two). Scoring functions After mutating the model input DNA sequences predictions are created using the models and those predictions then have to compared by scoring methods. Not all scoring methods are compatible with all models depending on the output data range of the model (see below). The compatibility of a scoring function with a given model can be indicated by setting scoring_functions in model.yaml: postprocessing: variant_effects seq_input: - seq scoring_functions: - name: diff type: diff - type: logit default: true The scoring function is identified by the type field in scoring_functions which is the only mandatory field. Allowed values for the type field are: diff , logit , deepsea_effect and custom . Setting default:true for a scoring function indicates that that respective scoring function is executed by variant effect prediction if none is selected by the used on execution time. If multiple scoring functions have set default:true then all of those will be run by default. If default:true is not set for any scoring function defined in scoring_functions then all entries in scoring_functions will be run by default. Scoring functions can be assigned a different name with the name flag by which they are then selected using the command line interface. In general it is not advisable to rename the scoring functions that come with Kipoi. Diff The simplest scoring method is to calculate the difference between predictions for the reference and the alternative allele: prediction(alt) - prediction(ref) . This scoring method is available for all models no matter if it is defined in scoring_functions or not. Logit Calculates the difference of logit-transformed values of the predictions: logit(prediction(alt)) - logit(prediction(ref)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1]. LogitAlt Returns the logits transformed predictions for the sequences carrying the alternative allele: logit(prediction(alt)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1]. LogitRef Returns the logits transformed predictions for the sequences carrying the reference allele: logit(prediction(ref)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1]. Deepsea_effect Calculates the variant scores as defined in the publication of the DeepSEA model (Troyanskaya et al., 2015) by using the absolute value of the logit difference and diff values multiplied together: abs(Logit * Diff) with Logit and Diff defined as above. Custom Custom scoring methods can be defined and shipped with the models. In that case the model.yaml will look similar to this: postprocessing: variant_effects: seq_input: - seq scoring_functions: - name: my_scores type: custom defined_as: postproc.py::myfun args: first_arg: doc: Description of the first argument default: 1 Notice that the selection of type: custom requires that defined_as is set. The value postproc.py::myfun indicates that the callable python object myfun is stored in a file called postproc.py . When executing variant effect prediction in the command line the scoring function can be chosen by it's name - which in this case is: my_scores . All scoring functions are subclasses of Rc_merging_pred_analysis this means that also a custom scoring function must inherit from it. Output The output of variant effect prediction is by default stored in a VCF that is derived from the input VCF. The output VCF only contains variants for which a effect prediction could be generated (e.g. if no model input sample overlapped a variant no prediction could be made for it). The predictions themselves are stored in the INFO field of the VCF, with the ID starting with KPVEP and containing the name of the model. Additional to the predictions themselves a also a region ID will be stored in a second INFO field. The region IDs are the values stored in model_input['metadata']['ranges']['id'] given to a sequence sample generated by the dataloader. This way it is possible to trace back which sequence was mutated by which variant in order to produce a certain effect prediction Since multiple seqeunces generated by the dataloader may overlap one variant - especially when using the overlap-based effect prediction - it is possible that the generated VCF output will contain a variant multiple times, but the different predictions will be destinguishable by their region ID. If variant effect prediction is run programmatically in python then the results are returned as a dictionary of pandas DataFrames. More complex models More complex models may have more than only one DNA sequence input, it may even be that models have DNA sequence inputs taken from different regions of the genome within one sample in a batch. See this sketch for an illustration of the scenario: The dataloader has three sequence outputs which are linked to two metadata ranges. for both ranges objects the beginning of the ranges is displayed. In order to overlap the metadata ranges with variants the input batch is processed one sample at a time. The samples in a batch are displayed in green rectangular boxes: For every sample all the ranges are assembled and overlapped with variants in the VCF. Then the effect is predicted for every single variant in the VCF that overlaps at least one of the region defined in that sample. This means that for the first sample in the batch two variants are investigated: rs1 and rs2. rs1 can only affect seq1a and seq1b, hence those two sequences are mutated, seq2 is not. rs2 overlaps with both ranges in the first sample and hence two sequences are mutated with rs2 to predict its effect. This means that the first sample will be evaluated twice using variants rs1 and rs2, and the second sample only once using rs3.","title":"Variant effect prediction"},{"location":"overview/#variant-effect-prediction","text":"Variant effect prediction offers a simple way predict effects of SNVs using any model that uses DNA sequence as an input. Many different scoring methods can be chosen but the principle relies on in-silico mutagenesis (see below). The default input is a VCF and the default output again is a VCF annotated with predictions of variant effects.","title":"Variant effect prediction"},{"location":"overview/#how-it-works","text":"This sketch highlights the overall functionality of variant effect prediction. More details are given in the chapters below. Dataloader output and a VCF are overlapped and the input DNA sequence is mutated as defined in the VCF. The reference and the alternative set of model inputs is predicted using the model and the differences are evaluated using a scoring function. The results are then stored in an annotated VCF.","title":"How it works"},{"location":"overview/#in-silico-mutagenesis","text":"The principle relies on generating model predictions twice, once with DNA sequence that contains the reference and once with the alternative allele of a variant. Those predictions can then be compared in different ways to generate an effect prediction.","title":"In-silico mutagenesis"},{"location":"overview/#scoring-methods","text":"Scoring methods that come with Kipoi are Diff which simply calculates the difference between the two predictions, Logit which calculates the difference of logit(prediction) of the two predictions and a few more. Those scoring methods can also be user-defined in which case they can be submitted with the model. Not all scoring functions are compatible with all model possible model outputs - for example the logit transformation can only be performed on values [0,1].","title":"Scoring methods"},{"location":"overview/#model-and-dataloader-requirements","text":"The model has to produce predictions at least partly based on DNA sequence and the DNA sequence either has to be as a string (e.g. acgtACGT ) or in a 1-hot encoded way in which A = [1,0,0,0] , C = [0,1,0,0] , G= [0,0,1,0] , T= [0,0,0,1] . Please note that any letter/base that is not in acgtACGT will be regarded and treated as N (in one-hot: [0,0,0,0] )! Requirements for the dataloader are that apart from producing the model input it also has to output information which region of the genome this generated sequence corresponds. On a side note: This region is only used to calculate an overlap with the query VCF, hence as long the dataloader output refers to the same sequence assembly as the VCF file variant scoring will return the desired results.","title":"Model and dataloader requirements"},{"location":"overview/#setting-up-the-modelyaml","text":"In order to indicate that a model is compatible with Kipoi postprocessing the definition of postprocessing in the model.yaml file is necessary. The postprocessing section can then mention multiple different ways to interpret a model. Here we will discuss variant effect prediction, a sample section of the model.yaml can look like this: postprocessing: variant_effects: seq_input: - seq use_rc: seq_only This defines that the current model is capable to be used for variant effect prediction ( variant_effects ) and it defines that seq is the name of the model input that contains DNA sequence, which can be mutated and used for effect prediction. seq_input is a mandatory field and variant effect prediction can only be executed if there is at least one model input defined in seq_input . For some models it is necessary that also reverse-complements of DNA sequences are tested / predicted. To indicate that this is the case for the current model add the optional flag use_rc: seq_only . Using seq_only will reverse-complement only the model inputs that are defined in seq_input . Any other model input will remain untouched and exactly the same input will be fed to the model input as for the \"forward\" version of the model input. As mentioned above the DNA sequence input may either be a string or 1-hot encoded. To indicate which format is used the special_type flag is used. The model input may then look like this: schema: inputs: seq: shape: (101, 4) special_type: DNASeq doc: One-hot encoded RNA sequence Here a one-hot encoded sequence ( DNASeq ) is expected to be the model input. Note that the model input label (here: seq ) was used before in the postprocessing section and the same label is expected to be exist in the dataloader output. The special_type flag for using string input sequences is: DNAStringSeq . So the following snippet of a model.yaml file schema: inputs: seq: shape: () special_type: DNAStringSeq doc: RNA sequence as a string indicates that a single sample of seq is np.array(string) where string is a python string. If special_type is not defined for a model input, but it is used in seq_input in the postprocessing section, then by default Kipoi expects one-hot encoded DNA sequences.","title":"Setting up the model.yaml"},{"location":"overview/#setting-up-the-dataloaderyaml","text":"Similar to the model.yaml also dataloader.yaml has to have a postprocessing section defined to indicate that it is compatible with variant effect prediction. As a bare minimum the following has to be defined: postprocessing: variant_effects: And equally important every DNA sequence input of a model (here seq ) has to have an associated metadata tag, which could like follows: output_schema: inputs: seq: shape: (101, 4) special_type: DNASeq doc: One-hot encoded RNA sequence associated_metadata: ranges some_other_input: shape: (1, 10) doc: Some description metadata: ranges: type: GenomicRanges doc: Ranges describing inputs.seq Here the associated_metadata flag in the input field seq is set to ranges , which means that for every sample in the model_input['inputs']['seq'] one entry in model_input['metadata']['ranges'] is expected with its type either being GenomicRanges or a dictionary of numpy arrays with the keys chr , start , end , id . The information in the metadata object gives variant effect prediction the possibilty to find the relative position of a variant within a given input sequence. Hence the associated_metadata is mandatory for every entry in seq_input in the model.yaml file. Please note that the coordinates in the metadata are expected to be 0-based, hence comply with .bed file format! The following sketch gives an overview how the different tags play together and how they are used with variant effect prediction.","title":"Setting up the dataloader.yaml"},{"location":"overview/#use-cases","text":"This section describes a set of functions which cover most of the common queries for variant effect. All of the functions described below require that the model.yaml and dataloader.yaml files are set up in the way defined above. In literature in-silico mutagenesis-based variant effect predcition is performed in a variant centric way: Starting from a VCF for every variant a sequence centered on said variant is generated. That sequence is then mutated by modifying the central base and setting it to what is defined as reference or alternative allele, generating two sets of sequences. For both the set with the reference allele in the center and the alternative allele in the center the model prediction is run and model outputs are compared. Not all models can predict on aribrary DNA sequences from any region of the genome. Splicing models may for example only be trained on regions surrounding a splice site, hence the variant-centered approach from before will not work. Therefore two more options to run variant effect predicion are offered: restricted variant centered effect prediction and overlap-based effect prediction. Variant effect prediction will try to use variant-centered approaches whenever the bed_input flag is defined in dataloader.yaml (see below). Otherwise the overlap-based effect prediction is used. This is because the variant centered approach is generally faster and for every variant in the VCF one single prediction can be made (assuming the position of variant is in a valid genomic region). For all the methods described below it is essential that genomic coordinates in the VCF and the coordinates used by the dataloader are for the same genome / assembly /etc.","title":"Use-cases"},{"location":"overview/#variant-centered-effect-prediction","text":"In order to use variant centered effect prediction the dataloader must accept an input bed file based on which it will produce model input. Furthermore the dataloader is required to return the name values (fourth column) of the input bed file in the id field of model_input['metadata']['ranges'] . Additionally the order of samples has to be identical with the order of regions in the input bed file, but regions may be skipped. In order for the variant effect prediction to know which input argument of the dataloader is accepts a bed file three additional lines in dataloader.yaml are necessary, e.g: postprocessing: variant_effects: bed_input: - intervals_file This section indicates that the dataloader function has an argument intervals_file which accepts a bed file path as input which may be used.","title":"Variant centered effect prediction"},{"location":"overview/#restricted-variant-centered-effect-prediction","text":"Requirements for the dataloader and dataloader.yaml here are identical to the variant centered effect prediction. The only difference is that this function is designed for models that can't predict on arbitrary regions of the genome, but only in certain regions of the genome. If those regions can be defined in a bed file (further on called 'restriction-bed' file) then this approach can be used. Variant effect prediction will then intersect the VCF with the restriction-bed and generate another bed file that is then passed on to the dataloader. Regions in the restriction-bed file may be larger than the input sequence lenght, in that case the generated seuqence will be centered on the variant position as much as possible - restricted by what is defined in the restrictions-bed file.","title":"Restricted-variant centered effect prediction"},{"location":"overview/#overlap-based-effect-prediction","text":"If the dataloader does not support bed input files then variant effect predictions can be run by the overlap of a VCF with the regions defined in the metdata output of the dataloader. If multiple variants overlap with a region then the effect will be predicted inpendently for those variants. If multiple (e.g.: two) model input samples overlap with one variant then the output will contain as many predictions as there were independent overlaps of metadata ranges and variants (e.g.: two).","title":"Overlap-based effect prediction"},{"location":"overview/#scoring-functions","text":"After mutating the model input DNA sequences predictions are created using the models and those predictions then have to compared by scoring methods. Not all scoring methods are compatible with all models depending on the output data range of the model (see below). The compatibility of a scoring function with a given model can be indicated by setting scoring_functions in model.yaml: postprocessing: variant_effects seq_input: - seq scoring_functions: - name: diff type: diff - type: logit default: true The scoring function is identified by the type field in scoring_functions which is the only mandatory field. Allowed values for the type field are: diff , logit , deepsea_effect and custom . Setting default:true for a scoring function indicates that that respective scoring function is executed by variant effect prediction if none is selected by the used on execution time. If multiple scoring functions have set default:true then all of those will be run by default. If default:true is not set for any scoring function defined in scoring_functions then all entries in scoring_functions will be run by default. Scoring functions can be assigned a different name with the name flag by which they are then selected using the command line interface. In general it is not advisable to rename the scoring functions that come with Kipoi.","title":"Scoring functions"},{"location":"overview/#diff","text":"The simplest scoring method is to calculate the difference between predictions for the reference and the alternative allele: prediction(alt) - prediction(ref) . This scoring method is available for all models no matter if it is defined in scoring_functions or not.","title":"Diff"},{"location":"overview/#logit","text":"Calculates the difference of logit-transformed values of the predictions: logit(prediction(alt)) - logit(prediction(ref)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1].","title":"Logit"},{"location":"overview/#logitalt","text":"Returns the logits transformed predictions for the sequences carrying the alternative allele: logit(prediction(alt)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1].","title":"LogitAlt"},{"location":"overview/#logitref","text":"Returns the logits transformed predictions for the sequences carrying the reference allele: logit(prediction(ref)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1].","title":"LogitRef"},{"location":"overview/#deepsea_effect","text":"Calculates the variant scores as defined in the publication of the DeepSEA model (Troyanskaya et al., 2015) by using the absolute value of the logit difference and diff values multiplied together: abs(Logit * Diff) with Logit and Diff defined as above.","title":"Deepsea_effect"},{"location":"overview/#custom","text":"Custom scoring methods can be defined and shipped with the models. In that case the model.yaml will look similar to this: postprocessing: variant_effects: seq_input: - seq scoring_functions: - name: my_scores type: custom defined_as: postproc.py::myfun args: first_arg: doc: Description of the first argument default: 1 Notice that the selection of type: custom requires that defined_as is set. The value postproc.py::myfun indicates that the callable python object myfun is stored in a file called postproc.py . When executing variant effect prediction in the command line the scoring function can be chosen by it's name - which in this case is: my_scores . All scoring functions are subclasses of Rc_merging_pred_analysis this means that also a custom scoring function must inherit from it.","title":"Custom"},{"location":"overview/#output","text":"The output of variant effect prediction is by default stored in a VCF that is derived from the input VCF. The output VCF only contains variants for which a effect prediction could be generated (e.g. if no model input sample overlapped a variant no prediction could be made for it). The predictions themselves are stored in the INFO field of the VCF, with the ID starting with KPVEP and containing the name of the model. Additional to the predictions themselves a also a region ID will be stored in a second INFO field. The region IDs are the values stored in model_input['metadata']['ranges']['id'] given to a sequence sample generated by the dataloader. This way it is possible to trace back which sequence was mutated by which variant in order to produce a certain effect prediction Since multiple seqeunces generated by the dataloader may overlap one variant - especially when using the overlap-based effect prediction - it is possible that the generated VCF output will contain a variant multiple times, but the different predictions will be destinguishable by their region ID. If variant effect prediction is run programmatically in python then the results are returned as a dictionary of pandas DataFrames.","title":"Output"},{"location":"overview/#more-complex-models","text":"More complex models may have more than only one DNA sequence input, it may even be that models have DNA sequence inputs taken from different regions of the genome within one sample in a batch. See this sketch for an illustration of the scenario: The dataloader has three sequence outputs which are linked to two metadata ranges. for both ranges objects the beginning of the ranges is displayed. In order to overlap the metadata ranges with variants the input batch is processed one sample at a time. The samples in a batch are displayed in green rectangular boxes: For every sample all the ranges are assembled and overlapped with variants in the VCF. Then the effect is predicted for every single variant in the VCF that overlaps at least one of the region defined in that sample. This means that for the first sample in the batch two variants are investigated: rs1 and rs2. rs1 can only affect seq1a and seq1b, hence those two sequences are mutated, seq2 is not. rs2 overlaps with both ranges in the first sample and hence two sequences are mutated with rs2 to predict its effect. This means that the first sample will be evaluated twice using variants rs1 and rs2, and the second sample only once using rs3.","title":"More complex models"},{"location":"using/","text":"Postprocessing Kipoi offers a set of postprocessing tools that enable to calculate variant effects, create mutation maps, inspect activation of hidden model layers and to calculate the gradient of layer activation with respect to a given input. Variant effect prediction and mutation map generation is available for all models where the variant_effects parameter in the model.yaml (and dataloader.yaml) is set (see here)[http://kipoi.org/docs/postprocessing/variant_effect_prediction]. Inspection of the activation of hidden model layers and calculation of gradients is available for all deep learning models: Currently supported are Keras, PyTorch and Tensorflow models. For a detailed description and examples of how to use tose features please take a look at: Variant effect prediction Mutation maps (Intermediate) layer activation extraction Gradient calculation Using variant effect prediction This chapter describes how to run variant prediction using a model in the zoo either using the python functionality or using the command line. A prerequesite is that the model is compatible with variant effect prediction (see: Variant effect prediction prerequesites for the model.yaml and dataloader.yaml) Variant effect prediction in python Using variant effect prediction within python allows more flexibility in the finegrain details compared to using the command line interface. The core function of variant effect prediction is score_variants , which on the one hand requires a model with its dataloader as well as a valid VCF. The easiest way to run variant effect prediction is the following: from kipoi.postprocessing.variant_effects import score_variants dataloader_arguments = {...} score_variants(model = \"my_model_name\", dl_args = dataloader_arguments, input_vcf = \"path/to/my_vcf.vcf\", output_vcf = \"path/to/my_annotated_vcf.vcf\",) Where model is a kipoi model - replace my_model_name by a valid model name. dataloader_arguments contains all the kwargs that are necessary to run the dataloader. The coordinates in the input_vcf have to match the genome / assembly etc. of the raw input files used by the dataloader. The output of score_variants is an annotated VCF - output_vcf . For more details please look at the detailed function description of score_variants . For details on the different scoring methods please take a look at the detailed explanation of variant effect prediction or the API defintion. The above code will run the dataloader based with dataloader_arguments and try to overlap the input VCF with the sequences generated by the dataloader. If a model dataloader accepts bed files input to control the generated regions, then a temporary bed file with variant-centered regions will be generated. If the dataloader does not offer a bed file input then the inputs generated by the dataloader will automatically be overlapped with the positions in the VCF and only the overlapping regions / variants are tested. For more control over the region generation please use kipoi.postprocessing.variant_effects.predict_snvs function's vcf_to_region argument with SnvCenteredRg , SnvPosRestrictedRg , or None . In the following section features of both functions score_variants and predict_snvs will be explained - please keep in mind that score_variants is a wrapper function around predict_snvs to cover most frequent use cases and reduce complexity of the user's code. Test region generation based on VCFs: Variant-centered effect prediction In the above example the regions were defined by the dataloader arguments, but if the dataloader supports bed file input (see dataloader.yaml definition for variant effect prediction) then the SnvCenteredRg class can generate a temporary bed file using a VCF and information on the required input sequence length from the model.yaml which is extracted by the ModelInfoExtractor instance model_info : from kipoi.postprocessing.variant_effects import SnvCenteredRg vcf_to_region = SnvCenteredRg(model_info) The resulting vcf_to_region object can then be used as the vcf_to_region argument when calling predict_snvs . Restricted variant-centered effect prediction This funcionality is similar to variant-centered effect prediction - the only difference is that this function is designed for models that can't predict on arbitrary regions of the genome, but only in certain regions of the genome. If those regions can be defined in a bed file (further on called 'restriction-bed' file) then this approach can be used. Variant effect prediction will then intersect the VCF with the restriction-bed and generate another bed file that is then passed on to the dataloader. Regions in the restriction-bed file may be larger than the input sequence lenght, in that case the generated seuqence will be centered on the variant position as much as possible - restricted by what is defined in the restrictions-bed file. The SnvPosRestrictedRg class can generate a temporary bed file using a VCF, the restrictions-bed file ( restricted_regions_fpath in the example below) and information on the required input sequence length from the model.yaml which is extracted by the ModelInfoExtractor instance model_info : from kipoi.postprocessing.variant_effects import SnvPosRestrictedRg import pybedtools as pb pbd = pb.BedTool(restricted_regions_fpath) vcf_to_region = SnvPosRestrictedRg(model_info, pbd) The resulting vcf_to_region object can then be used as the vcf_to_region argument when calling predict_snvs . Scoring functions Scoring functions perform calculations on the model predictions for the reference and alternative sequences. Default scoring functions are: Logit , LogitAlt , LogitRef , Diff , DeepSEA_effect . These functions are described in more detail in the variant effect prediction pages. These and custom scoring functions can be used in the score_variants function by setting the scores as a list of strings, for example: [\"logit\", \"diff\"] . This list can contain strings of the implemented scoring functions ( \"diff\" , \"ref\" , \"alt\" , \"logit\" , \"logit_ref\" , \"logit_alt\" , \"deepsea_effect\" ) or callables that are inherited from RCScore . Fine-tuning scoring functions The default scoring functions ( Logit , LogitAlt , LogitRef , Diff , DeepSEA_effect ) offer different options on how the forward and the reverse complement sequences are merged together. They have an rc_merging argument which can be \"min\" , \"max\" , \"mean\" , \"median\" or \"absmax\" . So when using the score_variants function the maximum between forward and reverse complement sequences for the alt-ref prediction differences should be returned, then the scores_kargs argument would be: [{\"rc_merging\": \"max\"}] and scores would be [\"diff\"] . The default rc_merging value is \"mean\" . Saving mutated sequence sets to a file A specialised feature of the predict_snvs function that is only available when using the python functions is to save the mutated sequence sets in a file. This can be useful for quality control or if a non-deeplearning model outside the model zoo should be run using the same data. For those cases instances of the SyncHdf5SeqWriter can be used. If they are passed to predict_snvs as the argument generated_seq_writer then the respective sequences are written to a file. Keep in mind that when defining a generated_seq_writer then no actual effect prediction is performed, but only the reference/alternative sequence sets are generated and saved. Return predictions By default effect predicions are not kept in memory, but only written to the output VCF to ensure a low memory profile. By setting the parameter return_predictions = True in predict_snvs or in score_variants the effect predictions are accumulated in memory and the results are returned as a dictionary of DataFrames, where the keys are the labels of the used scoring functions and the DataFrames have the shape (number effect predictions, number of output tasks of the model). Using the command line interface Similar to kipoi predict variant effect prediction can be run by executing: kipoi postproc score_variants my_model_name \\ --dataloader_args '{...}' \\ --vcf_path path/to/my_vcf.vcf \\ --out_vcf_fpath path/to/my_annotated_vcf.vcf Exceptions are that if the dataloader of the model allows the definition of a bed input file, then the respective field in the --dataloader_args JSON will be replaced by a bed file that consists in regions that are centered on the variant position. That is, if in the dataloader.yaml file of the respective model the bed_input flag is set then the respective argument in the --dataloader_args will be overwritten. When using variant effect prediction from the command line and using --source dir , keep in mind that whatever the path is that you put where my_model_name stands in the above command is treated as your model name. Since the annotated VCF INFO tags contain the model name as an identifier, executing kipoi postproc score_variants ./ --source dir ... will result in an annotated VCF with the model name \".\", which is most probably not desired. For those cases kipoi postproc score_variants ... should be executed in at least one directory level higher than the one where the model.yaml file lies. Then the command will look similar to this kipoi postproc score_variants ./my_model --source dir ... and the annotated VCF INFO tags will contain './my_model'. Scoring functions Scoring functions perform calculations on the model predictions for the reference and alternative sequences. Default scoring functions are: logit , logit_alt , logit_ref , diff , deepsea_effect . These functions are described in more detail in the variant effect prediction pages. Given a model is compatible with said scoring functions one or more of those can be selected by using the --scoring argument, e.g.: --scoring diff logit . The model.yaml file defines which scoring functions are available for a model, with the exception that the diff scoring function is available for all models. In the model.yaml also additional custom scoring functions can be defined, for details on please see the variant effect prediction pages. The labels by which the different scoring functions are made available can also be defined in the model.yaml file using the name tag. Fine-tuning scoring functions Scoring functions may have or may even require arguments at instantiation. Those arguments can be passed as JSON dictionaries to scoring functions by using the --scoring_kwargs argument. If --scoring_kwargs is used then for every label set in --scoring there must be a --scoring_kwargs JSON in the exact same order. If the degault values should be used or no arguments are required then an empty dictionary ( {} ) can be used. For example: --scoring diff my_scr --scoring_kwargs '{}' '{my_arg:2}' will use diff with the default parameters and will instantiate my_scr(my_arg=2) . The default scoring functions ( logit , logit_alt , logit_ref , diff , deepsea_effect ) offer different options on how the forward and the reverse complement sequences are merged together. They have an rc_merging argument which can be \"min\" , \"max\" , \"mean\" , \"median\" or \"absmax\" . So if the maximum between forward and reverse complement sequences for the alt-ref prediction differences should be returned, then the command would be: --scoring diff --scoring_kwargs '{rc_merging:\"max\"}' . By default rc_merging is set to \"mean\" . Mutation maps Mutation maps are related to variant effect prediction discussed above. Mutation maps are the application of SNV variant effect prediction on every position of the input sequence with all three alternative alleles. Therefore mutation maps can only be generated for models that support variant effect prediction. Mutation maps can be used to give an overview over the effect scores in a selected region. This region may be centered on a variant of interest or any other region in the genome for which the model can produce a prediction. It is therefore complementary to the variant effect prediction functionality and is intended for use with less variants / regions of interest as the variant effect prediction itself. Typically a mutation map should be calculated for only a handful of regions or query variants (that each tag a region), because for every region many effect predictions have to calculated resulting in calculation time and memory requirements: For a single query variant / query region N = model_sequence_length * 3 * model_output_tasks * effect_scoring_functions effect predictions have to be performed. The workflow is desinged in two steps: In a first step the aforementioned calculation is performed and results are stored in an hdf5 file with standardised format. These files can then be imported into the visualisation part of mutation maps. Both steps are available in python, R as well as the command line. Calculating mutation maps Python / R API The core element of mutation maps is the MutationMap class that is instantiated with a Kipoi model object, a dataloader object and the dataloader arguments: import kipoi from kipoi.postprocessing.variant_effects import MutationMap model = kipoi.get_model(<model_name>) dataloader = model.default_dataloader dataloader_arguments = {...} mm = MutationMap(model, dataloader, dataloader_arguments) MutationMap instances have the following methods to calculate mutation maps for the given query regions / variants: query_region , query_bed , query_vcf . All those functions return an instance of MutationMapPlotter, which can be stored as a hdf5 file or directly be used for generating mutation map plots. query_region The query_region command can be used to generate a mutation map for a selected genomic region: mmp = mm.query_region(\"chr22\", 25346, 25357) The query region has to be transformed to match model input sequence length as well as it has to lie in a genomic region for which the model can produce prediction. All this is taken care of automatically just like in the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below . query_bed The query_bed command can be used to generate mutation maps for genomic regions defined in the bed file: mmp = mm.query_region(\"path/to/my/file.bed\") The query regions have to be transformed to match model input sequence length as well as they hasveto lie in a genomic region for which the model can produce prediction. All this is taken care of automatically just like in the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below . query_vcf The query_vcf command can be used to generate mutation maps based on variants defined in the vcf file: mmp = mm.query_vcf(\"path/to/my/file.vcf\") The regions for query variants are generated analogously to the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below . MutationMapPlotter Instances of the MutationMapPlotter class are generated by the query_* methods of the MutationMap class. They contain all the effect predictions plus some additional meta data necessary to produce mutation map plots. Those objects can be stored in hdf5 files. For plotting the plot_mutmap function can be used. The required arguments select the input sequence by a numerical index ( input_entry ), the name of the DNA sequence model input ( model_seq_input ), the name of the scoring function for which the results should be displayed ( scoring_key ) and finally the model output task ( model_output ). A combination of those four values directly link to one set of mutation map predictions. input_entry input_entry is a numerical index indicating which set of input data should be used. This relates back to how query regions are turned into model input data, see below . Since this link depends model sequence length as well as whether the model can only predict for a restricted subset of he genome, the meaning of an index value may vary from model to model. For a combination of models with highly different model input specifications it is therefore advisable to only query a single variant or region in order to avoid confusion. model_seq_input Many models will only have a single model input key, so this parameter might seem superfluous, but in general a model can have multiple DNA sequence inputs which are all being tested for variant effects. scoring_key The scoring key is one of the labels passed to the query_* function in the scores argument. model_output model_output is a model output task label. Additional to the required arguments the plots can be generated for a subset of the model input sequence using the limit_region_genomic . The plot can be generated with reverse-complementation of the sequence by using rc_plot . There are additional features available for the python/R API which are described in the method definition, some of which are also used in the mutation_map.ipynb . The CLI In the CLI mutation maps can be calculated for bed files or for VCF files. Both file formats are accepted by the --regions_file argument of the CLI command: kipoi postproc create_mutation_map <my_model_name> --dataloader_args '{...}' --regions_file path/to/my/file.vcf --output path/to/the/results/file.hdf5 Plotting Plotting in the command line works analogously as using the python API: kipoi postproc plot_mutation_map --input_file path/to/the/results/file.hdf5 --input_entry 0 --model_seq_input seq --scoring_key diff --model_output my_model_task --output path/to/the/plot/file.png The meaning of the parameters is identical to the ones in the python API mentioned above. The plotting functionality in the CLI is limited to zooming into genomic region and reverse-complementation of sequences. For examaples please take a look at the mutation_map.ipynb . Transformation of queries to model input In order to perform a query on a model the query input must be transformed into genomic regions compatible with the model. Similar to variant effect prediction using the score_variants the automatically chosen region generation method will be chosen based on whether a dataloader offers a bed file input for postprocessing. dataloader.yaml > postprocessing > variant_effects > bed_input . By setting this value the mutation map method will automatically generate a temporary bed input file requesting model input for genomic regions. The path of this temporary bed file is then passed on to the dataloader by resetting the respective argument in the datalaoder_arguments . For some models it is not possible to freely define the genomic region for which model input data should be generated - in that case the dataloader.yaml does not have the dataloader.yaml > postprocessing > variant_effects > bed_input set. In those cases the datalaoder is executed without modifying the dataloader_arguments . The metadata generated alongside the model input is then used to identify model input that overlaps a query region / query variant. For cases when genomic regions can be defined freely for a model, the input samples will always have to generated matching the model input sequence length. This means that for query variants a region of the length of the model input will be centered on the query variant position. For query regions (e.g.: bed input file) every region is overlapped with windows of length of the model input. The first of those regions will start at the same position as the selected query region. Regions of the length of the model input sequence length will then be generated consecutively in order to cover the full region defined by the respective query region - see this schematic: In the top bit of this schematic on can see the case in which the dataloader accepts a bed file as an input to generate model input data. This also requires the correct setup of the dataloader.yaml in postprocessing > variant_effects > bed_input as described in more detail (here)[../postprocessing/variant_effect_prediction]. When the dataloader doesn't support bed input files for region defintion then all the regions generated by the dataloader will be overlapped with the query regions and any overlapping data generated from the dataloader will be used for mutation maps. The same as for bed query files holds true for VCF query files. As mentioned above all of those model input sequences are the subjected to variant effect prediction for every base and ever possible allele. The integer numbers displayed in the green or orange boxes are te order in which model input data is processed by the mutation map calculation algorithm. The numbers represent the index by which the predictions can then be accessed for plotting ( input_entry in plot_mutmap method of MutationMapPlotter or --input_entry CLI argument). Layer activation extraction Similar to model prediction on a batch of input data it is possible to predict the activation of intermediate layers. The layer can be selected using the layer argument and the value has to be the identifier of the respective layer. python / R API In python and R intermediate (hidden) layer activation can be calculated using the predict_activation_on_batch method of Kipoi models implementing the LayerActivationMixin . All deep learning frameworks supported by Kipoi implement this mixin: import kipoi # Get the model model = kipoi.get_model(\"my_model_name\") dataloader_arguments = {...} # Get the dataloader iterator dl_iterator = model.default_dataloader(**dataloader_arguments).iterator() # Get layer activation res = model.predict_activation_on_batch(dl_iterator.__next__(), layer = \"layer_of_interest\") CLI The prediction of layer activation using the command line works by adding the --layer argument to the prediction command: kipoi predict my_model_name --dataloader_arguments '{...}' --layer 'layer_of_interest' --output path/to/output/file.<tsv/hdf5/bed> Gradient calculation The calculation of gradients of the activation of a layer with respect to input data has proven to be a powerful tool for model and data interpretation. This approach can explain which portions of the model input were important for a given model output or for a given activation of a hidden layer. This feature is known as saliency maps . A successor, which relates gradients to the respective model input is the grad input_ score, which is - as its name implies - a multiplication of the first order gradient on the input data with the input data itself. _grad input for genomics models is seen as an alterntiave / complement to perturbation-based approaches like variant effect prediction. The advantage of gradient-based approaches being that in a single calculation step the importance of all bases in an input DNA sqeuence is established at the same time. Additionally gradient based approaches are not limited to Kipoi models that support variant effect prediction, and therefore are usable on all deep learning models. Finally gradient-based approaches highlight the input feature importance for all model inputs at once, also taking interactions between input into account, which cannot be done in variant effect prediction (perturbation-based approaches). Even though deep learning frameworks come with automatic gradient calculation as one of their core features, the accessibility of this functionality to the user is generally not straight forward and may vary from framework version to version. Kipoi comes with a consistent API to extract gradients for the Keras, PyTorch, and Tensorflow frameworks. The API takes advantage of the individual implementations of the automatic differentiation algorithm and in the frameworks, supporting multiple versions of those frameworks. To offer a consistent design the gradient can only be calculated with respect to model input - not with respect to the input of a hidden layer. What is essentially needed in terms of parameters to perform the calculation is: the Kipoi model instance, the Kipoi model input data (generated by a dataloader), an identifier of the (hidden) layer from which (backwards) the gradient should be calculated ( layer ). The gradient can in most frameworks only be calculated on a scalar. To ensure compatibility Kipoi therefore uses averaging functions ( avg_func ) that average across the outputs of a layer. Amongst those the summation ( sum ), maximum ( max ), minimum ( min ) and the maximum of absolute values ( absmax ) are available. To allow more fine-grain control the user can subset outputs ( filter_idx ) of a selected layer that are then passed to the averaging function. The filter_idx arguments takes integers, slice objects, and any tuple consisting in combinations of integers and slice objects. What is passed to filter_idx will be used to select from the model layer output, it must therefore be compatible with the layer output shape. To simplify the process for users who want to calculate the gradient starting from the model output (final layer) the final_layer argument can be used instead of explicitely selecting the layer by its ids with layer . This functionality has to be used with caution, as models may contain post-processing layers or non-linear activation functions as their final layer. Gradient calculation with respect to those values is generally not recommended. To overcome the problem of the last layer being a non-linear activation function another argument pre_nonlinearity was imlemented that tries to traverse the model graph from the selected layer towards model input in case the selected layer is a non-linear activation function. The pre_nonlinearity cannot be implemented for all models and using it may raise Exceptions in case the selected Kipoi model cannot support that feature. It is generally advisable to select a layer explicitely by using the ( layer ) to ensure that the desired calculations are being performed. Gradient visualisation To complete the model gradient calculation Kipoi comes with gradient visualisation tools, that can distinguish between 1-hot encoded DNA sequence model input and other model input. The default plotting function for 1-hot encoded DNA sequence is a seq-logo plot displaying the prediction output as letter height. In case type of a model input is unknown or it is not DNA sequence a heatmap will be generated. In any case the visualisation tools are only available for one- or two-dimensional input data. An additional feature is the generation of a bedgraph file instead of a heatmap/seqlogo plot. In the general case a seq_dim parameter has to be set defining the dimension in which every entry corresponds to one genomic position in a consecutive order. The GradPlotter class which is repsonsible for gradient visualisations has a plot function that has only one required argument sample . sample is the integer index of dataloader sample for which the plot should be produced. Python / R API All of the arguments mentioned above are available within the grad_input method of Kipoi models that implement GradientMixin . Namely those are KerasModel , PyTorchModel , and TensorflowModel . For an example please refer to the grad_input.ipynb . The returned output from the grad_input matches the structre of the inputs entry of the data batch generated by the model dataloader. CLI The command line interface is designed in analogy with the model prediction functionality plus the arguments exlpained above. The output can be stored in a tsv or an hdf5 file. In case a hdf5 output is chosen the gradient visualisation methods that come with Kipoi can be used. For an example please refer to the grad_input.ipynb .","title":"Postprocessing"},{"location":"using/#postprocessing","text":"Kipoi offers a set of postprocessing tools that enable to calculate variant effects, create mutation maps, inspect activation of hidden model layers and to calculate the gradient of layer activation with respect to a given input. Variant effect prediction and mutation map generation is available for all models where the variant_effects parameter in the model.yaml (and dataloader.yaml) is set (see here)[http://kipoi.org/docs/postprocessing/variant_effect_prediction]. Inspection of the activation of hidden model layers and calculation of gradients is available for all deep learning models: Currently supported are Keras, PyTorch and Tensorflow models. For a detailed description and examples of how to use tose features please take a look at: Variant effect prediction Mutation maps (Intermediate) layer activation extraction Gradient calculation","title":"Postprocessing"},{"location":"using/#using-variant-effect-prediction","text":"This chapter describes how to run variant prediction using a model in the zoo either using the python functionality or using the command line. A prerequesite is that the model is compatible with variant effect prediction (see: Variant effect prediction prerequesites for the model.yaml and dataloader.yaml)","title":"Using variant effect prediction"},{"location":"using/#variant-effect-prediction-in-python","text":"Using variant effect prediction within python allows more flexibility in the finegrain details compared to using the command line interface. The core function of variant effect prediction is score_variants , which on the one hand requires a model with its dataloader as well as a valid VCF. The easiest way to run variant effect prediction is the following: from kipoi.postprocessing.variant_effects import score_variants dataloader_arguments = {...} score_variants(model = \"my_model_name\", dl_args = dataloader_arguments, input_vcf = \"path/to/my_vcf.vcf\", output_vcf = \"path/to/my_annotated_vcf.vcf\",) Where model is a kipoi model - replace my_model_name by a valid model name. dataloader_arguments contains all the kwargs that are necessary to run the dataloader. The coordinates in the input_vcf have to match the genome / assembly etc. of the raw input files used by the dataloader. The output of score_variants is an annotated VCF - output_vcf . For more details please look at the detailed function description of score_variants . For details on the different scoring methods please take a look at the detailed explanation of variant effect prediction or the API defintion. The above code will run the dataloader based with dataloader_arguments and try to overlap the input VCF with the sequences generated by the dataloader. If a model dataloader accepts bed files input to control the generated regions, then a temporary bed file with variant-centered regions will be generated. If the dataloader does not offer a bed file input then the inputs generated by the dataloader will automatically be overlapped with the positions in the VCF and only the overlapping regions / variants are tested. For more control over the region generation please use kipoi.postprocessing.variant_effects.predict_snvs function's vcf_to_region argument with SnvCenteredRg , SnvPosRestrictedRg , or None . In the following section features of both functions score_variants and predict_snvs will be explained - please keep in mind that score_variants is a wrapper function around predict_snvs to cover most frequent use cases and reduce complexity of the user's code.","title":"Variant effect prediction in python"},{"location":"using/#test-region-generation-based-on-vcfs","text":"","title":"Test region generation based on VCFs:"},{"location":"using/#variant-centered-effect-prediction","text":"In the above example the regions were defined by the dataloader arguments, but if the dataloader supports bed file input (see dataloader.yaml definition for variant effect prediction) then the SnvCenteredRg class can generate a temporary bed file using a VCF and information on the required input sequence length from the model.yaml which is extracted by the ModelInfoExtractor instance model_info : from kipoi.postprocessing.variant_effects import SnvCenteredRg vcf_to_region = SnvCenteredRg(model_info) The resulting vcf_to_region object can then be used as the vcf_to_region argument when calling predict_snvs .","title":"Variant-centered effect prediction"},{"location":"using/#restricted-variant-centered-effect-prediction","text":"This funcionality is similar to variant-centered effect prediction - the only difference is that this function is designed for models that can't predict on arbitrary regions of the genome, but only in certain regions of the genome. If those regions can be defined in a bed file (further on called 'restriction-bed' file) then this approach can be used. Variant effect prediction will then intersect the VCF with the restriction-bed and generate another bed file that is then passed on to the dataloader. Regions in the restriction-bed file may be larger than the input sequence lenght, in that case the generated seuqence will be centered on the variant position as much as possible - restricted by what is defined in the restrictions-bed file. The SnvPosRestrictedRg class can generate a temporary bed file using a VCF, the restrictions-bed file ( restricted_regions_fpath in the example below) and information on the required input sequence length from the model.yaml which is extracted by the ModelInfoExtractor instance model_info : from kipoi.postprocessing.variant_effects import SnvPosRestrictedRg import pybedtools as pb pbd = pb.BedTool(restricted_regions_fpath) vcf_to_region = SnvPosRestrictedRg(model_info, pbd) The resulting vcf_to_region object can then be used as the vcf_to_region argument when calling predict_snvs .","title":"Restricted variant-centered effect prediction"},{"location":"using/#scoring-functions","text":"Scoring functions perform calculations on the model predictions for the reference and alternative sequences. Default scoring functions are: Logit , LogitAlt , LogitRef , Diff , DeepSEA_effect . These functions are described in more detail in the variant effect prediction pages. These and custom scoring functions can be used in the score_variants function by setting the scores as a list of strings, for example: [\"logit\", \"diff\"] . This list can contain strings of the implemented scoring functions ( \"diff\" , \"ref\" , \"alt\" , \"logit\" , \"logit_ref\" , \"logit_alt\" , \"deepsea_effect\" ) or callables that are inherited from RCScore .","title":"Scoring functions"},{"location":"using/#fine-tuning-scoring-functions","text":"The default scoring functions ( Logit , LogitAlt , LogitRef , Diff , DeepSEA_effect ) offer different options on how the forward and the reverse complement sequences are merged together. They have an rc_merging argument which can be \"min\" , \"max\" , \"mean\" , \"median\" or \"absmax\" . So when using the score_variants function the maximum between forward and reverse complement sequences for the alt-ref prediction differences should be returned, then the scores_kargs argument would be: [{\"rc_merging\": \"max\"}] and scores would be [\"diff\"] . The default rc_merging value is \"mean\" .","title":"Fine-tuning scoring functions"},{"location":"using/#saving-mutated-sequence-sets-to-a-file","text":"A specialised feature of the predict_snvs function that is only available when using the python functions is to save the mutated sequence sets in a file. This can be useful for quality control or if a non-deeplearning model outside the model zoo should be run using the same data. For those cases instances of the SyncHdf5SeqWriter can be used. If they are passed to predict_snvs as the argument generated_seq_writer then the respective sequences are written to a file. Keep in mind that when defining a generated_seq_writer then no actual effect prediction is performed, but only the reference/alternative sequence sets are generated and saved.","title":"Saving mutated sequence sets to a file"},{"location":"using/#return-predictions","text":"By default effect predicions are not kept in memory, but only written to the output VCF to ensure a low memory profile. By setting the parameter return_predictions = True in predict_snvs or in score_variants the effect predictions are accumulated in memory and the results are returned as a dictionary of DataFrames, where the keys are the labels of the used scoring functions and the DataFrames have the shape (number effect predictions, number of output tasks of the model).","title":"Return predictions"},{"location":"using/#using-the-command-line-interface","text":"Similar to kipoi predict variant effect prediction can be run by executing: kipoi postproc score_variants my_model_name \\ --dataloader_args '{...}' \\ --vcf_path path/to/my_vcf.vcf \\ --out_vcf_fpath path/to/my_annotated_vcf.vcf Exceptions are that if the dataloader of the model allows the definition of a bed input file, then the respective field in the --dataloader_args JSON will be replaced by a bed file that consists in regions that are centered on the variant position. That is, if in the dataloader.yaml file of the respective model the bed_input flag is set then the respective argument in the --dataloader_args will be overwritten. When using variant effect prediction from the command line and using --source dir , keep in mind that whatever the path is that you put where my_model_name stands in the above command is treated as your model name. Since the annotated VCF INFO tags contain the model name as an identifier, executing kipoi postproc score_variants ./ --source dir ... will result in an annotated VCF with the model name \".\", which is most probably not desired. For those cases kipoi postproc score_variants ... should be executed in at least one directory level higher than the one where the model.yaml file lies. Then the command will look similar to this kipoi postproc score_variants ./my_model --source dir ... and the annotated VCF INFO tags will contain './my_model'.","title":"Using the command line interface"},{"location":"using/#scoring-functions_1","text":"Scoring functions perform calculations on the model predictions for the reference and alternative sequences. Default scoring functions are: logit , logit_alt , logit_ref , diff , deepsea_effect . These functions are described in more detail in the variant effect prediction pages. Given a model is compatible with said scoring functions one or more of those can be selected by using the --scoring argument, e.g.: --scoring diff logit . The model.yaml file defines which scoring functions are available for a model, with the exception that the diff scoring function is available for all models. In the model.yaml also additional custom scoring functions can be defined, for details on please see the variant effect prediction pages. The labels by which the different scoring functions are made available can also be defined in the model.yaml file using the name tag.","title":"Scoring functions"},{"location":"using/#fine-tuning-scoring-functions_1","text":"Scoring functions may have or may even require arguments at instantiation. Those arguments can be passed as JSON dictionaries to scoring functions by using the --scoring_kwargs argument. If --scoring_kwargs is used then for every label set in --scoring there must be a --scoring_kwargs JSON in the exact same order. If the degault values should be used or no arguments are required then an empty dictionary ( {} ) can be used. For example: --scoring diff my_scr --scoring_kwargs '{}' '{my_arg:2}' will use diff with the default parameters and will instantiate my_scr(my_arg=2) . The default scoring functions ( logit , logit_alt , logit_ref , diff , deepsea_effect ) offer different options on how the forward and the reverse complement sequences are merged together. They have an rc_merging argument which can be \"min\" , \"max\" , \"mean\" , \"median\" or \"absmax\" . So if the maximum between forward and reverse complement sequences for the alt-ref prediction differences should be returned, then the command would be: --scoring diff --scoring_kwargs '{rc_merging:\"max\"}' . By default rc_merging is set to \"mean\" .","title":"Fine-tuning scoring functions"},{"location":"using/#mutation-maps","text":"Mutation maps are related to variant effect prediction discussed above. Mutation maps are the application of SNV variant effect prediction on every position of the input sequence with all three alternative alleles. Therefore mutation maps can only be generated for models that support variant effect prediction. Mutation maps can be used to give an overview over the effect scores in a selected region. This region may be centered on a variant of interest or any other region in the genome for which the model can produce a prediction. It is therefore complementary to the variant effect prediction functionality and is intended for use with less variants / regions of interest as the variant effect prediction itself. Typically a mutation map should be calculated for only a handful of regions or query variants (that each tag a region), because for every region many effect predictions have to calculated resulting in calculation time and memory requirements: For a single query variant / query region N = model_sequence_length * 3 * model_output_tasks * effect_scoring_functions effect predictions have to be performed. The workflow is desinged in two steps: In a first step the aforementioned calculation is performed and results are stored in an hdf5 file with standardised format. These files can then be imported into the visualisation part of mutation maps. Both steps are available in python, R as well as the command line.","title":"Mutation maps"},{"location":"using/#calculating-mutation-maps","text":"","title":"Calculating mutation maps"},{"location":"using/#python-r-api","text":"The core element of mutation maps is the MutationMap class that is instantiated with a Kipoi model object, a dataloader object and the dataloader arguments: import kipoi from kipoi.postprocessing.variant_effects import MutationMap model = kipoi.get_model(<model_name>) dataloader = model.default_dataloader dataloader_arguments = {...} mm = MutationMap(model, dataloader, dataloader_arguments) MutationMap instances have the following methods to calculate mutation maps for the given query regions / variants: query_region , query_bed , query_vcf . All those functions return an instance of MutationMapPlotter, which can be stored as a hdf5 file or directly be used for generating mutation map plots.","title":"Python / R API"},{"location":"using/#query_region","text":"The query_region command can be used to generate a mutation map for a selected genomic region: mmp = mm.query_region(\"chr22\", 25346, 25357) The query region has to be transformed to match model input sequence length as well as it has to lie in a genomic region for which the model can produce prediction. All this is taken care of automatically just like in the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below .","title":"query_region"},{"location":"using/#query_bed","text":"The query_bed command can be used to generate mutation maps for genomic regions defined in the bed file: mmp = mm.query_region(\"path/to/my/file.bed\") The query regions have to be transformed to match model input sequence length as well as they hasveto lie in a genomic region for which the model can produce prediction. All this is taken care of automatically just like in the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below .","title":"query_bed"},{"location":"using/#query_vcf","text":"The query_vcf command can be used to generate mutation maps based on variants defined in the vcf file: mmp = mm.query_vcf(\"path/to/my/file.vcf\") The regions for query variants are generated analogously to the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below .","title":"query_vcf"},{"location":"using/#mutationmapplotter","text":"Instances of the MutationMapPlotter class are generated by the query_* methods of the MutationMap class. They contain all the effect predictions plus some additional meta data necessary to produce mutation map plots. Those objects can be stored in hdf5 files. For plotting the plot_mutmap function can be used. The required arguments select the input sequence by a numerical index ( input_entry ), the name of the DNA sequence model input ( model_seq_input ), the name of the scoring function for which the results should be displayed ( scoring_key ) and finally the model output task ( model_output ). A combination of those four values directly link to one set of mutation map predictions.","title":"MutationMapPlotter"},{"location":"using/#input_entry","text":"input_entry is a numerical index indicating which set of input data should be used. This relates back to how query regions are turned into model input data, see below . Since this link depends model sequence length as well as whether the model can only predict for a restricted subset of he genome, the meaning of an index value may vary from model to model. For a combination of models with highly different model input specifications it is therefore advisable to only query a single variant or region in order to avoid confusion.","title":"input_entry"},{"location":"using/#model_seq_input","text":"Many models will only have a single model input key, so this parameter might seem superfluous, but in general a model can have multiple DNA sequence inputs which are all being tested for variant effects.","title":"model_seq_input"},{"location":"using/#scoring_key","text":"The scoring key is one of the labels passed to the query_* function in the scores argument.","title":"scoring_key"},{"location":"using/#model_output","text":"model_output is a model output task label. Additional to the required arguments the plots can be generated for a subset of the model input sequence using the limit_region_genomic . The plot can be generated with reverse-complementation of the sequence by using rc_plot . There are additional features available for the python/R API which are described in the method definition, some of which are also used in the mutation_map.ipynb .","title":"model_output"},{"location":"using/#the-cli","text":"In the CLI mutation maps can be calculated for bed files or for VCF files. Both file formats are accepted by the --regions_file argument of the CLI command: kipoi postproc create_mutation_map <my_model_name> --dataloader_args '{...}' --regions_file path/to/my/file.vcf --output path/to/the/results/file.hdf5","title":"The CLI"},{"location":"using/#plotting","text":"Plotting in the command line works analogously as using the python API: kipoi postproc plot_mutation_map --input_file path/to/the/results/file.hdf5 --input_entry 0 --model_seq_input seq --scoring_key diff --model_output my_model_task --output path/to/the/plot/file.png The meaning of the parameters is identical to the ones in the python API mentioned above. The plotting functionality in the CLI is limited to zooming into genomic region and reverse-complementation of sequences. For examaples please take a look at the mutation_map.ipynb .","title":"Plotting"},{"location":"using/#transformation-of-queries-to-model-input","text":"In order to perform a query on a model the query input must be transformed into genomic regions compatible with the model. Similar to variant effect prediction using the score_variants the automatically chosen region generation method will be chosen based on whether a dataloader offers a bed file input for postprocessing. dataloader.yaml > postprocessing > variant_effects > bed_input . By setting this value the mutation map method will automatically generate a temporary bed input file requesting model input for genomic regions. The path of this temporary bed file is then passed on to the dataloader by resetting the respective argument in the datalaoder_arguments . For some models it is not possible to freely define the genomic region for which model input data should be generated - in that case the dataloader.yaml does not have the dataloader.yaml > postprocessing > variant_effects > bed_input set. In those cases the datalaoder is executed without modifying the dataloader_arguments . The metadata generated alongside the model input is then used to identify model input that overlaps a query region / query variant. For cases when genomic regions can be defined freely for a model, the input samples will always have to generated matching the model input sequence length. This means that for query variants a region of the length of the model input will be centered on the query variant position. For query regions (e.g.: bed input file) every region is overlapped with windows of length of the model input. The first of those regions will start at the same position as the selected query region. Regions of the length of the model input sequence length will then be generated consecutively in order to cover the full region defined by the respective query region - see this schematic: In the top bit of this schematic on can see the case in which the dataloader accepts a bed file as an input to generate model input data. This also requires the correct setup of the dataloader.yaml in postprocessing > variant_effects > bed_input as described in more detail (here)[../postprocessing/variant_effect_prediction]. When the dataloader doesn't support bed input files for region defintion then all the regions generated by the dataloader will be overlapped with the query regions and any overlapping data generated from the dataloader will be used for mutation maps. The same as for bed query files holds true for VCF query files. As mentioned above all of those model input sequences are the subjected to variant effect prediction for every base and ever possible allele. The integer numbers displayed in the green or orange boxes are te order in which model input data is processed by the mutation map calculation algorithm. The numbers represent the index by which the predictions can then be accessed for plotting ( input_entry in plot_mutmap method of MutationMapPlotter or --input_entry CLI argument).","title":"Transformation of queries to model input"},{"location":"using/#layer-activation-extraction","text":"Similar to model prediction on a batch of input data it is possible to predict the activation of intermediate layers. The layer can be selected using the layer argument and the value has to be the identifier of the respective layer.","title":"Layer activation extraction"},{"location":"using/#python-r-api_1","text":"In python and R intermediate (hidden) layer activation can be calculated using the predict_activation_on_batch method of Kipoi models implementing the LayerActivationMixin . All deep learning frameworks supported by Kipoi implement this mixin: import kipoi # Get the model model = kipoi.get_model(\"my_model_name\") dataloader_arguments = {...} # Get the dataloader iterator dl_iterator = model.default_dataloader(**dataloader_arguments).iterator() # Get layer activation res = model.predict_activation_on_batch(dl_iterator.__next__(), layer = \"layer_of_interest\")","title":"python / R API"},{"location":"using/#cli","text":"The prediction of layer activation using the command line works by adding the --layer argument to the prediction command: kipoi predict my_model_name --dataloader_arguments '{...}' --layer 'layer_of_interest' --output path/to/output/file.<tsv/hdf5/bed>","title":"CLI"},{"location":"using/#gradient-calculation","text":"The calculation of gradients of the activation of a layer with respect to input data has proven to be a powerful tool for model and data interpretation. This approach can explain which portions of the model input were important for a given model output or for a given activation of a hidden layer. This feature is known as saliency maps . A successor, which relates gradients to the respective model input is the grad input_ score, which is - as its name implies - a multiplication of the first order gradient on the input data with the input data itself. _grad input for genomics models is seen as an alterntiave / complement to perturbation-based approaches like variant effect prediction. The advantage of gradient-based approaches being that in a single calculation step the importance of all bases in an input DNA sqeuence is established at the same time. Additionally gradient based approaches are not limited to Kipoi models that support variant effect prediction, and therefore are usable on all deep learning models. Finally gradient-based approaches highlight the input feature importance for all model inputs at once, also taking interactions between input into account, which cannot be done in variant effect prediction (perturbation-based approaches). Even though deep learning frameworks come with automatic gradient calculation as one of their core features, the accessibility of this functionality to the user is generally not straight forward and may vary from framework version to version. Kipoi comes with a consistent API to extract gradients for the Keras, PyTorch, and Tensorflow frameworks. The API takes advantage of the individual implementations of the automatic differentiation algorithm and in the frameworks, supporting multiple versions of those frameworks. To offer a consistent design the gradient can only be calculated with respect to model input - not with respect to the input of a hidden layer. What is essentially needed in terms of parameters to perform the calculation is: the Kipoi model instance, the Kipoi model input data (generated by a dataloader), an identifier of the (hidden) layer from which (backwards) the gradient should be calculated ( layer ). The gradient can in most frameworks only be calculated on a scalar. To ensure compatibility Kipoi therefore uses averaging functions ( avg_func ) that average across the outputs of a layer. Amongst those the summation ( sum ), maximum ( max ), minimum ( min ) and the maximum of absolute values ( absmax ) are available. To allow more fine-grain control the user can subset outputs ( filter_idx ) of a selected layer that are then passed to the averaging function. The filter_idx arguments takes integers, slice objects, and any tuple consisting in combinations of integers and slice objects. What is passed to filter_idx will be used to select from the model layer output, it must therefore be compatible with the layer output shape. To simplify the process for users who want to calculate the gradient starting from the model output (final layer) the final_layer argument can be used instead of explicitely selecting the layer by its ids with layer . This functionality has to be used with caution, as models may contain post-processing layers or non-linear activation functions as their final layer. Gradient calculation with respect to those values is generally not recommended. To overcome the problem of the last layer being a non-linear activation function another argument pre_nonlinearity was imlemented that tries to traverse the model graph from the selected layer towards model input in case the selected layer is a non-linear activation function. The pre_nonlinearity cannot be implemented for all models and using it may raise Exceptions in case the selected Kipoi model cannot support that feature. It is generally advisable to select a layer explicitely by using the ( layer ) to ensure that the desired calculations are being performed.","title":"Gradient calculation"},{"location":"using/#gradient-visualisation","text":"To complete the model gradient calculation Kipoi comes with gradient visualisation tools, that can distinguish between 1-hot encoded DNA sequence model input and other model input. The default plotting function for 1-hot encoded DNA sequence is a seq-logo plot displaying the prediction output as letter height. In case type of a model input is unknown or it is not DNA sequence a heatmap will be generated. In any case the visualisation tools are only available for one- or two-dimensional input data. An additional feature is the generation of a bedgraph file instead of a heatmap/seqlogo plot. In the general case a seq_dim parameter has to be set defining the dimension in which every entry corresponds to one genomic position in a consecutive order. The GradPlotter class which is repsonsible for gradient visualisations has a plot function that has only one required argument sample . sample is the integer index of dataloader sample for which the plot should be produced.","title":"Gradient visualisation"},{"location":"using/#python-r-api_2","text":"All of the arguments mentioned above are available within the grad_input method of Kipoi models that implement GradientMixin . Namely those are KerasModel , PyTorchModel , and TensorflowModel . For an example please refer to the grad_input.ipynb . The returned output from the grad_input matches the structre of the inputs entry of the data batch generated by the model dataloader.","title":"Python / R API"},{"location":"using/#cli_1","text":"The command line interface is designed in analogy with the model prediction functionality plus the arguments exlpained above. The output can be stored in a tsv or an hdf5 file. In case a hdf5 output is chosen the gradient visualisation methods that come with Kipoi can be used. For an example please refer to the grad_input.ipynb .","title":"CLI"},{"location":"api/imp/base/available_methods/","text":"available_methods available_methods() Get all available importance scores","title":"available_methods"},{"location":"api/imp/base/feature_importance/","text":"feature_importance feature_importance(model, dataloader, importance_score, importance_score_kwargs={}, batch_size=32, num_workers=0) Return feature importance scores Arguments model : kipoi model (obtained by kipoi.get_model() ) dataloader : instantiated kipoi dataloder (obtained by kipoi.get_dataloader_factory()(**dl_kwargs) or model.default_dataloader(**dl_kwargs) importance_score ( str or ImportanceScore ) : which importance score to use importance_score_kwargs (dict) : kwargs passed to the importance score batch_size : run scoring and data-loading in batches num_workers : number of workers for parallel data-loading. Passed to dataloader.batch_iter(...) Returns (dict of np.arrays) : dataset returned by the dataloader (dict with keys inputs , targets , metadata ) but with an additional importance_scores key","title":"feature_importance"},{"location":"api/imp/gradient/Gradient/","text":"Gradient Gradient(self, model, filter_idx=None, avg_func='sum', layer=None, selected_fwd_node=None, pre_nonlinearity=False) Compute the gradient w.r.t. input Arguments model : Kipoi model layer\" : Which output layer to use to make the predictions. If not specified, the final layer will be used. pre_nonlinearity : boolean flag indicating that it should checked whether the selected output is post activation function. If a non-linear activation function is used attempt to use its input. filter_idx : Filter index that should be inspected with gradients. If not set all filters will be used. avg_func : Averaging function to be applied across selected filters ( --filter_idx ) in layer --layer .\" selected_fwd_node : If the selected layer has multiple inbound connections in the graph then those can be selected here with an integer index. Not necessarily supported by all models.","title":"Gradient"},{"location":"api/imp/gradient/GradientXInput/","text":"GradientXInput GradientXInput(self, model, filter_idx=None, avg_func='sum', layer=None, selected_fwd_node=None, pre_nonlinearity=False) Mask the gradient by the input value: grad * input, where input is typically a one-hot-encoded array.","title":"GradientXInput"},{"location":"api/imp/gradient/Saliency/","text":"Saliency Saliency(self, model, filter_idx=None, avg_func='sum', layer=None, selected_fwd_node=None, pre_nonlinearity=False) Saliency map: absolute value of gradients w.r.t. input","title":"Saliency"},{"location":"api/imp/ism/Mutation/","text":"Mutation Mutation(self, model, model_input, scores=['diff'], score_kwargs=None, batch_size=32, output_sel_fn=None, id_value=0, category_axis=1, test_ref_ref=False) ISM for working with one-hot encoded inputs. Arguments model : Kipoi model model_input : which model input to mutate scores : a list of score names or score instances batch_size : batch size for calls to prediction. This is independent from the size of batch used with the score method. score_kwargs : Initialisation keyword arguments for scores . If not None then it is a list of kwargs dictionaries of the same length as scores output_sel_fn : Function used to select a model output. Only the selected output will be reported as a return value. id_value : Which value to use for the identity category_axis : Dimension in which the the one-hot category is stored. e.g. for a one-hot encoded DNA-sequence array with input shape (1000, 4) for a single sample, category_axis is 1, for (4, 1000) category_axis is 0. In the given dimension only one value is allowed to be non-zero, which is the selected one. test_ref_ref : Also perform ISM on the positions where the input data has a 1 already. kipoi_interpret.importance_scores.ism_scores Ref Ref(self, rc_merging='mean') ref - Ref. allele prediction Alt Alt(self, rc_merging='mean') alt - Alt. allele prediction Diff Diff(self, rc_merging='mean') diff - Prediction difference: diff = p_alt - p_ref LogitRef LogitRef(self, rc_merging='mean') logit_ref - Ref. allele prediction on the logit scale: np.log(p_alt / (1 - p_alt )) LogitAlt LogitAlt(self, rc_merging='mean') logit_alt - Alt. allele prediction on the logit scale: np.log(p_alt / (1 - p_alt )) Logit Logit(self, rc_merging='mean') logit - Compute the difference on the logit scale: logit_diff = log(p_alt / (1 - p_alt )) - log(p_ref / (1 - p_ref )) DeepSEA_effect DeepSEA_effect(self, rc_merging='mean') deepsea_effect - Score used by DeepSEA: abs(logit_diff) * abs(diff)","title":"Mutation"},{"location":"api/imp/referencebased/DeepLift/","text":"DeepLift DeepLift(self, model, output_layer, task_idx, preact=True, mxts_mode='rescale_conv_revealcancel_fc', batch_size=32) Wrapper around DeepLIFT Arguments model : Kipoi model output_layer (int) : selected Keras layer with respect to which the scores should be calculated task_idx (int) : Node/Neuron within the selected layer with respect to which the score should be calculated preact : !NOT YET IMPLEMENTED! Use values prior to activation - for now the default is True! mxts_mode : Selected score batch_size : Batch size for scoring","title":"DeepLift"},{"location":"tutorials/1-DNA-seq-model-example/","text":"Generated from notebooks/1-DNA-seq-model-example.ipynb Here is a short demonstration of Kipoi-interpret. import kipoi import kipoi_interpret from kipoi_veff.utils.plot import seqlogo_heatmap from concise.preprocessing.sequence import encodeDNA # list all available methods kipoi_interpret.importance_scores.available_methods() {'deeplift': kipoi_interpret.importance_scores.referencebased.DeepLift, 'grad': kipoi_interpret.importance_scores.gradient.Gradient, 'grad*input': kipoi_interpret.importance_scores.gradient.GradientXInput, 'intgrad': kipoi_interpret.importance_scores.referencebased.IntegratedGradients, 'mutation': kipoi_interpret.importance_scores.ism.Mutation, 'saliency': kipoi_interpret.importance_scores.gradient.Saliency} # Gradient-based methods from kipoi_interpret.importance_scores.gradient import Gradient, GradientXInput # In-silico mutagenesis-based methods from kipoi_interpret.importance_scores.ism import Mutation # DeepLift from kipoi_interpret.importance_scores.referencebased import DeepLift Setup Model: model = kipoi.get_model(\"DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1\") 2018-07-20 01:41:36,856 [INFO] git-lfs pull -I DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1/** 2018-07-20 01:41:36,923 [INFO] git-lfs pull -I DeepBind/template/** 2018-07-20 01:41:36,981 [INFO] model DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1 loaded 2018-07-20 01:41:37,014 [INFO] git-lfs pull -I DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1/./** 2018-07-20 01:41:37,068 [INFO] git-lfs pull -I DeepBind/template/** 2018-07-20 01:41:37,129 [INFO] dataloader DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1/. loaded 2018-07-20 01:41:37,140 [INFO] successfully loaded the dataloader from /home/avsec/.kipoi/models/DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1/dataloader.py::SeqDataset 2018-07-20 01:41:37,206 [INFO] successfully loaded model architecture from <_io.TextIOWrapper name='model_files/model.json' mode='r' encoding='UTF-8'> 2018-07-20 01:41:37,265 [INFO] successfully loaded model weights from model_files/model.h5 2018-07-20 01:41:37,267 [INFO] dataloader.output_schema is compatible with model.schema Sequence of interest: seq = \"ATGGGCCAGCACACAGACCAGCACGTTGCCCAGGAGCTGTGGGAGGAAGATAAGAGGTATGAACATGATTAGCAAAAGGGCCTAGCTTGGACTCAGAATAA\" seqa = encodeDNA([seq]) # one-hot-encode the sequence Gradient * input grxinp = GradientXInput(model) val = grxinp.score(seqa)[0] fig = plt.figure(figsize=(15,2.5)) seqlogo_heatmap(val, val.T, ax=plt.subplot()) <matplotlib.axes._subplots.AxesSubplot at 0x7f3ef9bbadd8> Gradient gr = Gradient(model) val = gr.score(seqa)[0] fig = plt.figure(figsize=(15,2.5)) seqlogo_heatmap(val, val.T, ax=plt.subplot()) <matplotlib.axes._subplots.AxesSubplot at 0x7f3ef9220668> In-silico mutagenesis # TODO - update the Mutate function. It should return the following: # prediction_value: # - array def to_array(isval): \"\"\"Temporary convert the output to a numpy array \"\"\" def to_vec(x): if x is None: return 0 else: if isinstance(x, list): return x[0] else: return x return np.array([[to_vec(y) for y in x] for x in isval]) ism = Mutation(model, \"seq\") val = to_array(ism.score(seqa)[0]) fig = plt.figure(figsize=(15,2.5)) seqlogo_heatmap(np.abs(val), val.T, ax=plt.subplot(), show_letter_scale=False) <matplotlib.axes._subplots.AxesSubplot at 0x7f3ef82f8160> DeepLift # Not a sequential model # dl = DeepLift(model, 'maximum_593', 0)","title":"DNA-seq model"},{"location":"tutorials/1-DNA-seq-model-example/#setup","text":"Model: model = kipoi.get_model(\"DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1\") 2018-07-20 01:41:36,856 [INFO] git-lfs pull -I DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1/** 2018-07-20 01:41:36,923 [INFO] git-lfs pull -I DeepBind/template/** 2018-07-20 01:41:36,981 [INFO] model DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1 loaded 2018-07-20 01:41:37,014 [INFO] git-lfs pull -I DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1/./** 2018-07-20 01:41:37,068 [INFO] git-lfs pull -I DeepBind/template/** 2018-07-20 01:41:37,129 [INFO] dataloader DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1/. loaded 2018-07-20 01:41:37,140 [INFO] successfully loaded the dataloader from /home/avsec/.kipoi/models/DeepBind/Homo_sapiens/TF/D00765.001_ChIP-seq_GATA1/dataloader.py::SeqDataset 2018-07-20 01:41:37,206 [INFO] successfully loaded model architecture from <_io.TextIOWrapper name='model_files/model.json' mode='r' encoding='UTF-8'> 2018-07-20 01:41:37,265 [INFO] successfully loaded model weights from model_files/model.h5 2018-07-20 01:41:37,267 [INFO] dataloader.output_schema is compatible with model.schema Sequence of interest: seq = \"ATGGGCCAGCACACAGACCAGCACGTTGCCCAGGAGCTGTGGGAGGAAGATAAGAGGTATGAACATGATTAGCAAAAGGGCCTAGCTTGGACTCAGAATAA\" seqa = encodeDNA([seq]) # one-hot-encode the sequence","title":"Setup"},{"location":"tutorials/1-DNA-seq-model-example/#gradient-input","text":"grxinp = GradientXInput(model) val = grxinp.score(seqa)[0] fig = plt.figure(figsize=(15,2.5)) seqlogo_heatmap(val, val.T, ax=plt.subplot()) <matplotlib.axes._subplots.AxesSubplot at 0x7f3ef9bbadd8>","title":"Gradient * input"},{"location":"tutorials/1-DNA-seq-model-example/#gradient","text":"gr = Gradient(model) val = gr.score(seqa)[0] fig = plt.figure(figsize=(15,2.5)) seqlogo_heatmap(val, val.T, ax=plt.subplot()) <matplotlib.axes._subplots.AxesSubplot at 0x7f3ef9220668>","title":"Gradient"},{"location":"tutorials/1-DNA-seq-model-example/#in-silico-mutagenesis","text":"# TODO - update the Mutate function. It should return the following: # prediction_value: # - array def to_array(isval): \"\"\"Temporary convert the output to a numpy array \"\"\" def to_vec(x): if x is None: return 0 else: if isinstance(x, list): return x[0] else: return x return np.array([[to_vec(y) for y in x] for x in isval]) ism = Mutation(model, \"seq\") val = to_array(ism.score(seqa)[0]) fig = plt.figure(figsize=(15,2.5)) seqlogo_heatmap(np.abs(val), val.T, ax=plt.subplot(), show_letter_scale=False) <matplotlib.axes._subplots.AxesSubplot at 0x7f3ef82f8160>","title":"In-silico mutagenesis"},{"location":"tutorials/1-DNA-seq-model-example/#deeplift","text":"# Not a sequential model # dl = DeepLift(model, 'maximum_593', 0)","title":"DeepLift"}]}